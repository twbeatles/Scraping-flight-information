
"""
Flight Scraper V2 - Playwright + Manual Mode
Uses Playwright for scraping with manual fallback when auto-extraction fails.
"""

import time
import os
import sys
import heapq
import threading
from collections import OrderedDict
from dataclasses import dataclass, asdict
from typing import List, Optional, Dict, Any, Callable
import logging
from playwright.sync_api import sync_playwright, Page, Browser, TimeoutError as PlaywrightTimeoutError

import config
import scraper_config 
from scraper_config import ScraperScripts

# ë¡œê±° ì„¤ì • (ì¤‘ë³µ í•¸ë“¤ëŸ¬ ë°©ì§€)
logger = logging.getLogger("ScraperV2")


# === ì‚¬ìš©ì ì •ì˜ ì˜ˆì™¸ í´ë˜ìŠ¤ ===

class ScraperError(Exception):
    """ìŠ¤í¬ë˜í¼ ê¸°ë³¸ ì˜ˆì™¸"""
    pass

class BrowserInitError(ScraperError):
    """ë¸Œë¼ìš°ì € ì´ˆê¸°í™” ì‹¤íŒ¨"""
    def __init__(self, message: str = "ë¸Œë¼ìš°ì €ë¥¼ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."):
        self.message = message
        super().__init__(self.message)

class NetworkError(ScraperError):
    """ë„¤íŠ¸ì›Œí¬ ì—°ê²° ì˜¤ë¥˜"""
    def __init__(self, message: str = "ë„¤íŠ¸ì›Œí¬ ì—°ê²°ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.", url: str = ""):
        self.message = message
        self.url = url
        super().__init__(f"{self.message} (URL: {url})" if url else self.message)

class DataExtractionError(ScraperError):
    """ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨"""
    def __init__(self, message: str = "í•­ê³µí¸ ë°ì´í„°ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."):
        self.message = message
        super().__init__(self.message)


class ManualModeActivationError(ScraperError):
    """ìë™ ì¶”ì¶œ ì‹¤íŒ¨ í›„ ìˆ˜ë™ ëª¨ë“œ í™œì„±í™”ê¹Œì§€ ì‹¤íŒ¨"""
    def __init__(self, message: str = "ìˆ˜ë™ ëª¨ë“œë¡œ ì „í™˜í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤."):
        self.message = message
        super().__init__(self.message)


@dataclass
class FlightResult:
    """í•­ê³µê¶Œ ê²€ìƒ‰ ê²°ê³¼"""
    airline: str
    price: int  # ì´ ê°€ê²© (ì™•ë³µ í•©ì‚°)
    currency: str = "KRW"
    departure_time: str = ""
    arrival_time: str = ""
    duration: str = ""
    stops: int = 0
    flight_number: str = ""
    source: str = "Interpark"
    # ê·€êµ­í¸ ì •ë³´ (ì™•ë³µì¸ ê²½ìš°)
    return_departure_time: str = ""
    return_arrival_time: str = ""
    return_duration: str = ""
    return_stops: int = 0
    is_round_trip: bool = False
    # êµ­ë‚´ì„ ìš©: ê°€ëŠ”í¸/ì˜¤ëŠ”í¸ ê°€ê²© ë¶„ë¦¬
    outbound_price: int = 0
    return_price: int = 0
    return_airline: str = ""  # ì˜¤ëŠ”í¸ í•­ê³µì‚¬ (êµ­ë‚´ì„  ë“± êµì°¨ í•­ê³µì‚¬ ì‹œ)

    
    def to_dict(self) -> Dict[str, Any]:
        return asdict(self)


class PlaywrightScraper:
    """Playwright ê¸°ë°˜ ìŠ¤í¬ë˜í¼ - ìˆ˜ë™ ëª¨ë“œ ì§€ì›
    
    ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì €ë¡œ ì‚¬ìš© ê°€ëŠ¥:
        with PlaywrightScraper() as scraper:
            results = scraper.search(...)
    """
    
    # êµ­ë‚´ì„  í•­ê³µì‚¬ ëª©ë¡ (ì¤‘ì•™ ê´€ë¦¬)
    DOMESTIC_AIRLINES = [
        'ëŒ€í•œí•­ê³µ', 'ì•„ì‹œì•„ë‚˜', 'ì œì£¼í•­ê³µ', 'ì§„ì—ì–´', 'í‹°ì›¨ì´',
        'ì—ì–´ë¶€ì‚°', 'ì—ì–´ì„œìš¸', 'ì´ìŠ¤íƒ€í•­ê³µ', 'í•˜ì´ì—ì–´', 'ì—ì–´í”„ë ˆë¯¸ì•„', 'í”Œë¼ì´ê°•ì›'
    ]
    
    def __init__(self):
        self.playwright = None
        self.browser: Optional[Browser] = None
        self.page: Optional[Page] = None
        self.context = None
        self.manual_mode = False
        self._last_is_domestic = False
        # ìŠ¤í¬ë¡¤ ì¶”ì ìš© ì¸ìŠ¤í„´ìŠ¤ ë³€ìˆ˜ ì´ˆê¸°í™”
        self._no_scroll_count = 0
        self._no_new_count = 0
        self._bottom_count = 0
    
    def __enter__(self):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì§„ì…"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ì»¨í…ìŠ¤íŠ¸ ë§¤ë‹ˆì € ì¢…ë£Œ - ë¦¬ì†ŒìŠ¤ ìë™ ì •ë¦¬"""
        self.close()
        return False  # ì˜ˆì™¸ëŠ” ì „íŒŒ
    
    def _init_browser(
        self,
        log_func: Callable[[str], None] = None,
        user_data_dir: Optional[str] = None,
        headless: bool = False,
        block_resources: bool = False,
    ) -> None:
        """ë¸Œë¼ìš°ì € ì´ˆê¸°í™” (Chrome > Edge > Chromium ìˆœì„œ ì‹œë„)
        
        Raises:
            BrowserInitError: ëª¨ë“  ë¸Œë¼ìš°ì € ì‹œì‘ì— ì‹¤íŒ¨í•  ê²½ìš°
        """
        def log(msg):
            if log_func:
                log_func(msg)
            logger.info(msg)
        
        log("ğŸŒ Playwright ë¸Œë¼ìš°ì € ì‹œì‘ ì¤‘...")
        
        # Playwright ë“œë¼ì´ë²„ ì´ˆê¸°í™”
        try:
            self.playwright = sync_playwright().start()
        except FileNotFoundError as e:
            error_msg = (
                "âŒ Playwright ë“œë¼ì´ë²„ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
                "í•´ê²° ë°©ë²•:\n"
                "1. ëª…ë ¹ í”„ë¡¬í”„íŠ¸ì—ì„œ ì‹¤í–‰: pip install playwright\n"
                "2. ê·¸ í›„ ì‹¤í–‰: playwright install\n\n"
                f"ìƒì„¸ ì˜¤ë¥˜: {e}"
            )
            logger.error(error_msg)
            raise BrowserInitError(error_msg)
        except Exception as e:
            error_msg = (
                f"âŒ Playwright ì´ˆê¸°í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\n\n"
                f"ì˜¤ë¥˜: {e}\n\n"
                "í•´ê²° ë°©ë²•:\n"
                "- playwright íŒ¨í‚¤ì§€ ì¬ì„¤ì¹˜: pip install --upgrade playwright"
            )
            logger.error(error_msg)
            raise BrowserInitError(error_msg)
        
        browser_args = [
            '--disable-blink-features=AutomationControlled',
            '--disable-dev-shm-usage',
            '--no-sandbox'
        ]
        
        browsers_to_try = [
            ("Chrome", "chrome"),
            ("Edge", "msedge"),
            ("Chromium (ë‚´ì¥)", None)
        ]
        
        last_error = None
        tried_browsers = []
        
        for browser_name, channel in browsers_to_try:
            try:
                log(f"  â†’ {browser_name} ì‹œë„ ì¤‘...")
                launch_options = {
                    "headless": bool(headless),
                    "args": browser_args
                }
                if channel:
                    launch_options["channel"] = channel

                if user_data_dir:
                    context_options = {
                        **launch_options,
                        "viewport": {"width": 1400, "height": 900},
                        "locale": "ko-KR",
                        "user_agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36"
                    }
                    self.context = self.playwright.chromium.launch_persistent_context(
                        user_data_dir, **context_options
                    )
                    self._configure_resource_blocking(block_resources)
                    log(f"  âœ… {browser_name} ì‹œì‘ ì„±ê³µ (Persistent Context)")
                else:
                    self.browser = self.playwright.chromium.launch(**launch_options)
                    log(f"  âœ… {browser_name} ì‹œì‘ ì„±ê³µ")
                return  # ì„±ê³µì‹œ ë°˜í™˜
            except Exception as e:
                last_error = e
                tried_browsers.append(f"{browser_name}: {str(e)[:50]}")
                logger.debug(f"{browser_name} ì‹œì‘ ì‹¤íŒ¨: {e}")
                continue
        
        # ëª¨ë“  ë¸Œë¼ìš°ì € ì‹œì‘ ì‹¤íŒ¨ - ìƒì„¸ ì•ˆë‚´ ë©”ì‹œì§€
        self.close()
        
        error_details = "\n".join(f"  â€¢ {b}" for b in tried_browsers)
        error_msg = (
            "âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ë¸Œë¼ìš°ì €ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\n\n"
            "ğŸ“‹ ì‹œë„í•œ ë¸Œë¼ìš°ì €:\n"
            f"{error_details}\n\n"
            "ğŸ’¡ í•´ê²° ë°©ë²• (íƒ 1):\n"
            "  1. Chrome ì„¤ì¹˜: https://www.google.com/chrome\n"
            "  2. Edge ì„¤ì¹˜: https://www.microsoft.com/edge\n"
            "  3. ë˜ëŠ” ëª…ë ¹ í”„ë¡¬í”„íŠ¸ì—ì„œ: playwright install chromium\n\n"
            "â€» Windows 10 ì´ìƒì—ëŠ” Edgeê°€ ê¸°ë³¸ ì„¤ì¹˜ë˜ì–´ ìˆìŠµë‹ˆë‹¤.\n"
            "   Edgeê°€ ìˆëŠ”ë°ë„ ì˜¤ë¥˜ê°€ ë°œìƒí•˜ë©´ Edgeë¥¼ ìµœì‹  ë²„ì „ìœ¼ë¡œ ì—…ë°ì´íŠ¸í•˜ì„¸ìš”."
        )
        logger.error(error_msg)
        raise BrowserInitError(error_msg)

    def _configure_resource_blocking(self, enabled: bool) -> None:
        """ìë™(headless) ê²€ìƒ‰ì—ì„œ ë¶ˆí•„ìš” ë¦¬ì†ŒìŠ¤ ìš”ì²­ì„ ì°¨ë‹¨í•œë‹¤."""
        if not enabled or not self.context:
            return

        blocked = set(getattr(scraper_config, "AUTO_BLOCK_RESOURCE_TYPES", ()))
        if not blocked:
            return

        def _route_handler(route, request):
            try:
                if request.resource_type in blocked:
                    route.abort()
                else:
                    route.continue_()
            except Exception:
                try:
                    route.continue_()
                except Exception:
                    pass

        try:
            self.context.route("**/*", _route_handler)
        except Exception as e:
            logger.debug(f"ë¦¬ì†ŒìŠ¤ ì°¨ë‹¨ ë¼ìš°íŠ¸ ì„¤ì • ì‹¤íŒ¨ (ë¬´ì‹œë¨): {e}")

    def _enter_manual_mode(
        self,
        url: str,
        profile_dir: str,
        is_domestic: bool,
        log_func: Callable[[str], None],
        reopen_visible: bool,
    ) -> bool:
        """ìˆ˜ë™ ëª¨ë“œ í™œì„±í™”. headless ìë™ ê²€ìƒ‰ì¸ ê²½ìš° visible ë¸Œë¼ìš°ì €ë¡œ ì¬ì˜¤í”ˆ."""
        if not reopen_visible and self.page is not None:
            self.manual_mode = True
            log_func("ğŸ–ï¸ ìˆ˜ë™ ëª¨ë“œ í™œì„±í™” - ë¸Œë¼ìš°ì €ì—ì„œ ê²°ê³¼ ë¡œë”© í›„ 'ì¶”ì¶œ' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”")
            return True

        if reopen_visible:
            log_func("ğŸ–ï¸ ìë™ ì¶”ì¶œ ì‹¤íŒ¨ - ìˆ˜ë™ ëª¨ë“œ ë¸Œë¼ìš°ì €ë¥¼ ì—¬ëŠ” ì¤‘...")
        else:
            log_func("ğŸ–ï¸ ìˆ˜ë™ ëª¨ë“œ ì¬ì´ˆê¸°í™”: ê¸°ì¡´ ë¸Œë¼ìš°ì € ì„¸ì…˜ì´ ì—†ì–´ ìƒˆë¡œ ì—½ë‹ˆë‹¤.")
        try:
            if reopen_visible or self.page is None:
                self.close()
                self._init_browser(
                    log_func=log_func,
                    user_data_dir=profile_dir,
                    headless=False,
                    block_resources=False,
                )
                if self.context is None and self.browser is not None:
                    self.context = self.browser.new_context(
                        viewport={"width": 1400, "height": 900},
                        locale="ko-KR",
                        user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36",
                    )
                self.page = self.context.new_page()

            if url:
                try:
                    self.page.goto(url, wait_until="domcontentloaded", timeout=scraper_config.PAGE_LOAD_TIMEOUT_MS)
                except PlaywrightTimeoutError:
                    log_func("âš ï¸ ìˆ˜ë™ ëª¨ë“œ í˜ì´ì§€ ë¡œë”© ì‹œê°„ ì´ˆê³¼ - ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
                except Exception as e:
                    log_func(f"âš ï¸ ìˆ˜ë™ ëª¨ë“œ í˜ì´ì§€ ì§„ì… ì‹¤íŒ¨: {e}")
            self._wait_for_results(is_domestic, lambda _msg: None)
            self.manual_mode = True
            log_func("ğŸ–ï¸ ìˆ˜ë™ ëª¨ë“œ í™œì„±í™” - ë¸Œë¼ìš°ì €ì—ì„œ ê²°ê³¼ ë¡œë”© í›„ 'ì¶”ì¶œ' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”")
            return True
        except Exception as e:
            logger.error(f"ìˆ˜ë™ ëª¨ë“œ ì „í™˜ ì‹¤íŒ¨: {e}", exc_info=True)
            self.close()
            self.manual_mode = False
            return False

    def _wait_for_results(self, is_domestic: bool, log_func: Callable[[str], None]) -> bool:
        if not self.page:
            return False
        timeout_ms = int(scraper_config.DATA_WAIT_TIMEOUT_SECONDS * 1000)
        if is_domestic:
            selectors = [
                "button:has-text(\"ì›\")",
                "text=/\\d{1,3}(,\\d{3})+\\s*ì›/"
            ]
        else:
            selectors = [
                "li[data-index]",
                "text=/\\d{1,3}(,\\d{3})+\\s*ì›/"
            ]
        per_timeout = max(1000, timeout_ms // max(len(selectors), 1))
        for selector in selectors:
            try:
                self.page.wait_for_selector(selector, timeout=per_timeout)
                return True
            except PlaywrightTimeoutError:
                if log_func:
                    log_func(f"âš ï¸ ê²°ê³¼ ëŒ€ê¸° ì‹¤íŒ¨: {selector}")
                continue
        return False

    def _wait_for_domestic_return_view(self) -> bool:
        """êµ­ë‚´ì„  ì™•ë³µì—ì„œ ì˜¤ëŠ”í¸ í™”ë©´ ì „í™˜ì„ wait_for_function ê¸°ë°˜ìœ¼ë¡œ í™•ì¸."""
        if not self.page:
            return False
        timeout_ms = int(max(5, scraper_config.DOMESTIC_RETURN_WAIT_TIMEOUT_SECONDS) * 1000)
        try:
            self.page.wait_for_function(
                """
                () => {
                    const bodyText = document.body?.innerText || '';
                    const priceNodes = document.querySelectorAll('button, li, span');
                    let priceCount = 0;
                    for (const node of priceNodes) {
                        const text = node.textContent || '';
                        if (/\\d{1,3}(,\\d{3})+\\s*ì›/.test(text)) {
                            priceCount += 1;
                            if (priceCount >= 5) break;
                        }
                    }
                    return bodyText.includes('ì˜¤ëŠ”í¸') && priceCount >= 5;
                }
                """,
                timeout=timeout_ms,
            )
            return True
        except PlaywrightTimeoutError:
            return False

    @staticmethod
    def _sort_and_limit_results(
        results: List[FlightResult],
        max_results: int,
        log_func: Optional[Callable[[str], None]] = None,
    ) -> List[FlightResult]:
        if not results:
            return []
        ordered = sorted(results, key=lambda x: x.price if x.price > 0 else float("inf"))
        if isinstance(max_results, int) and max_results > 0 and len(ordered) > max_results:
            if log_func:
                log_func(f"âš ï¸ ê²°ê³¼ {len(ordered)}ê°œ ì¤‘ ìƒìœ„ {max_results}ê°œë§Œ ìœ ì§€í•©ë‹ˆë‹¤.")
            return ordered[:max_results]
        return ordered

    def _combine_domestic_round_trip(
        self,
        outbound_flights: List[Dict[str, Any]],
        return_flights: List[Dict[str, Any]],
        max_results: int,
    ) -> List[FlightResult]:
        """êµ­ë‚´ì„  ì™•ë³µ ì¡°í•©ì„ dedup + top-k(ìµœì €ê°€) ë°©ì‹ìœ¼ë¡œ ìƒì„±."""
        outbound_flights = [
            f
            for f in outbound_flights
            if f.get("price", 0) > 0 and f.get("depTime") and f.get("arrTime")
        ]
        return_flights = [
            f
            for f in return_flights
            if f.get("price", 0) > 0 and f.get("depTime") and f.get("arrTime")
        ]
        if not outbound_flights or not return_flights:
            return []

        outbound_flights.sort(key=lambda x: x["price"])
        return_flights.sort(key=lambda x: x["price"])
        top_outbound = outbound_flights[: scraper_config.DOMESTIC_COMBINATION_TOP_N]
        top_return = return_flights[: scraper_config.DOMESTIC_COMBINATION_TOP_N]

        max_keep = max_results if isinstance(max_results, int) and max_results > 0 else len(top_outbound) * len(top_return)
        max_heap: List[tuple] = []
        seen = set()
        seq = 0

        for ob in top_outbound:
            for ret in top_return:
                total_price = ob["price"] + ret["price"]
                dedup_key = (
                    ob["airline"],
                    ret["airline"],
                    total_price,
                    ob["depTime"],
                    ret["depTime"],
                )
                if dedup_key in seen:
                    continue
                seen.add(dedup_key)
                seq += 1

                flight = FlightResult(
                    airline=ob["airline"],
                    price=total_price,
                    departure_time=ob["depTime"],
                    arrival_time=ob["arrTime"],
                    stops=ob["stops"],
                    source="Interpark (êµ­ë‚´ì„ )",
                    return_departure_time=ret["depTime"],
                    return_arrival_time=ret["arrTime"],
                    return_stops=ret["stops"],
                    is_round_trip=True,
                    outbound_price=ob["price"],
                    return_price=ret["price"],
                    return_airline=ret["airline"],
                )

                entry = (-total_price, -seq, flight)
                if len(max_heap) < max_keep:
                    heapq.heappush(max_heap, entry)
                    continue

                worst_price = -max_heap[0][0]
                worst_seq = -max_heap[0][1]
                if (total_price, seq) < (worst_price, worst_seq):
                    heapq.heapreplace(max_heap, entry)

        ranked = sorted(max_heap, key=lambda x: (-x[0], -x[1]))
        return [entry[2] for entry in ranked]
    
    def search(self, origin: str, destination: str, 
               departure_date: str, return_date: Optional[str] = None,
               adults: int = 1, cabin_class: str = "ECONOMY",
               max_results: int = 1000,
               emit: Callable[[str], None] = None) -> List[FlightResult]:
        """
        í•­ê³µê¶Œ ê²€ìƒ‰ (Playwright ì‚¬ìš©, ì‹¤íŒ¨ì‹œ ìˆ˜ë™ ëª¨ë“œ)
        êµ­ë‚´ì„ ì˜ ê²½ìš° ê°€ëŠ”í¸ ì„ íƒ í›„ ì˜¤ëŠ”í¸ ë°ì´í„° ì¶”ì¶œ
        
        Args:
            cabin_class: "ECONOMY" | "BUSINESS" | "FIRST"
        """
        # ì„±ëŠ¥ ì¸¡ì • ì‹œì‘
        search_start_time = time.time()
        
        def log(msg):
            if emit:
                emit(msg)
            logger.info(msg)
        
        results = []
        url = ""
        profile_dir = ""
        auto_headless = bool(getattr(scraper_config, "AUTO_SEARCH_HEADLESS", True))
        
        # êµ­ë‚´ì„  ì—¬ë¶€ í™•ì¸ (í•œêµ­ ë‚´ ê³µí•­)
        domestic_airports = {"ICN", "GMP", "CJU", "PUS", "TAE", "SEL"}
        origin_domestic = origin.upper() in domestic_airports or config.CITY_CODES_MAP.get(origin.upper(), origin.upper()) in domestic_airports
        dest_domestic = destination.upper() in domestic_airports or config.CITY_CODES_MAP.get(destination.upper(), destination.upper()) in domestic_airports
        is_domestic = origin_domestic and dest_domestic
        self._last_is_domestic = is_domestic
        
        # ì¢Œì„ë“±ê¸‰ ì„ íƒ (ê¸°ë³¸: ECONOMY)
        cabin = cabin_class.upper() if cabin_class else "ECONOMY"
        if cabin not in ["ECONOMY", "BUSINESS", "FIRST"]:
            cabin = "ECONOMY"
        
        try:
            # ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ì¿ í‚¤/ìŠ¤í† ë¦¬ì§€ ì €ì¥)
            if getattr(sys, 'frozen', False):
                 app_data = os.path.join(os.environ.get('LOCALAPPDATA', os.path.expanduser('~')), 'FlightBot')
                 profile_dir = os.path.join(app_data, "playwright_profile")
            else:
                 profile_dir = os.path.join(os.getcwd(), "playwright_profile")
            
            os.makedirs(profile_dir, exist_ok=True)

            # ë¸Œë¼ìš°ì € ì´ˆê¸°í™” (Persistent Context í¬í•¨)
            self._init_browser(
                log_func=log,
                user_data_dir=profile_dir,
                headless=auto_headless,
                block_resources=auto_headless,
            )
            
            if self.context is None:
                self.context = self.browser.new_context(
                    viewport={"width": 1400, "height": 900},
                    locale='ko-KR',
                    user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
                )
                self._configure_resource_blocking(auto_headless)
            
            self.page = self.context.new_page()
            
            # URL êµ¬ì„±
            # CITY_CODES_MAPì— ìˆìœ¼ë©´ ë„ì‹œ ì½”ë“œ(c:)ë¡œ, ì—†ìœ¼ë©´ ê³µí•­ ì½”ë“œ(a:)ë¡œ ì²˜ë¦¬
            origin_upper = origin.upper()
            dest_upper = destination.upper()
            
            if origin_upper in config.CITY_CODES_MAP:
                origin_code = config.CITY_CODES_MAP[origin_upper]
                origin_prefix = "c"
            else:
                origin_code = origin_upper
                origin_prefix = "a"
            
            if dest_upper in config.CITY_CODES_MAP:
                dest_code = config.CITY_CODES_MAP[dest_upper]
                dest_prefix = "c"
            else:
                dest_code = dest_upper
                dest_prefix = "a"
            
            if return_date:
                url = f"https://travel.interpark.com/air/search/{origin_prefix}:{origin_code}-{dest_prefix}:{dest_code}-{departure_date}/{dest_prefix}:{dest_code}-{origin_prefix}:{origin_code}-{return_date}?cabin={cabin}&infant=0&child=0&adult={adults}"
            else:
                url = f"https://travel.interpark.com/air/search/{origin_prefix}:{origin_code}-{dest_prefix}:{dest_code}-{departure_date}?cabin={cabin}&infant=0&child=0&adult={adults}"
            
            if is_domestic:
                log(f"ğŸ‡°ğŸ‡· êµ­ë‚´ì„  ê²€ìƒ‰ ëª¨ë“œ ({origin_code} â†’ {dest_code})")
            else:
                log(f"âœˆï¸ êµ­ì œì„  ê²€ìƒ‰ ëª¨ë“œ")
            if auto_headless:
                log("âš¡ ìë™ ê²€ìƒ‰ ìµœì í™” ëª¨ë“œ: Headless + ë¦¬ì†ŒìŠ¤ ì°¨ë‹¨")
            log(f"URL: {url}")
            
            try:
                self.page.goto(url, wait_until='domcontentloaded', timeout=scraper_config.PAGE_LOAD_TIMEOUT_MS)
            except PlaywrightTimeoutError:
                log("âš ï¸ í˜ì´ì§€ ë¡œë”© ì‹œê°„ ì´ˆê³¼ - ê³„ì† ì§„í–‰í•©ë‹ˆë‹¤.")
            except Exception as e:
                raise NetworkError("í˜ì´ì§€ ë¡œë”© ì‹¤íŒ¨", url) from e

            # ê²°ê³¼ ë¡œë”© ëŒ€ê¸°
            log("ê²°ê³¼ ë¡œë”© ëŒ€ê¸° ì¤‘...")
            found_data = self._wait_for_results(is_domestic, log)
            if not found_data:
                log("ë°ì´í„°ê°€ ì¶©ë¶„íˆ ë¡œë“œë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
            # êµ­ë‚´ì„  ì™•ë³µì˜ ê²½ìš°: ê°€ëŠ”í¸ ë°ì´í„° ë¨¼ì € ì¶”ì¶œ â†’ í´ë¦­ â†’ ì˜¤ëŠ”í¸ ì¶”ì¶œ â†’ ë³‘í•©
            if is_domestic and return_date and found_data:
                log("ğŸ‡°ğŸ‡· êµ­ë‚´ì„  ì™•ë³µ: ê°€ëŠ”í¸/ì˜¤ëŠ”í¸ ë¶„ë¦¬ ìˆ˜ì§‘ ì‹œì‘")
                
                try:
                    # Step 1: ê°€ëŠ”í¸ ë°ì´í„° ë¨¼ì € ì¶”ì¶œ (í´ë¦­ ì „)
                    log("ğŸ“‹ 1ë‹¨ê³„: ê°€ëŠ”í¸ ëª©ë¡ ì¶”ì¶œ ì¤‘...")
                    outbound_flights = self._extract_domestic_flights_data()
                    log(f"âœ… ê°€ëŠ”í¸ {len(outbound_flights)}ê°œ ë°œê²¬")
                    
                    if not outbound_flights:
                        log("âš ï¸ ê°€ëŠ”í¸ ë°ì´í„° ì—†ìŒ - ìˆ˜ë™ ëª¨ë“œ ê¶Œì¥")
                        entered_manual = self._enter_manual_mode(
                            url=url,
                            profile_dir=profile_dir,
                            is_domestic=is_domestic,
                            log_func=log,
                            reopen_visible=auto_headless,
                        )
                        if not entered_manual:
                            raise ManualModeActivationError("ê°€ëŠ”í¸ ë°ì´í„° ì—†ìŒ ì´í›„ ìˆ˜ë™ ëª¨ë“œ ì „í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
                        return results
                    
                    # Step 2: ê°€ëŠ”í¸ ì„ íƒ (ì˜¤ëŠ”í¸ í™”ë©´ìœ¼ë¡œ ì „í™˜)
                    log("ğŸ”„ 2ë‹¨ê³„: ê°€ëŠ”í¸ ì„ íƒ â†’ ì˜¤ëŠ”í¸ í™”ë©´ ì „í™˜...")
                    airlines_js = str(self.DOMESTIC_AIRLINES)  # Python ë¦¬ìŠ¤íŠ¸ë¥¼ JS ë°°ì—´ë¡œ ë³€í™˜
                    best_outbound = min(outbound_flights, key=lambda x: x.get('price', float('inf')))
                    price_text = f"{best_outbound.get('price', 0):,}ì›" if best_outbound.get('price') else ""
                    js_click = ScraperScripts.get_click_flight_by_details_script(
                        best_outbound.get('airline', ''),
                        best_outbound.get('depTime', ''),
                        best_outbound.get('arrTime', ''),
                        price_text
                    )
                    clicked = self.page.evaluate(js_click)
                    if not clicked:
                        js_click = ScraperScripts.get_click_flight_script(airlines_js)
                        clicked = self.page.evaluate(js_click)
                    
                    if not clicked:
                        log("âš ï¸ ê°€ëŠ”í¸ ì„ íƒ ì‹¤íŒ¨ - ê°€ëŠ”í¸ë§Œ ë°˜í™˜")
                        # ê°€ëŠ”í¸ë§Œ ê²°ê³¼ë¡œ ë°˜í™˜
                        for ob in outbound_flights:
                            results.append(FlightResult(
                                airline=ob['airline'],
                                price=ob['price'],
                                departure_time=ob['depTime'],
                                arrival_time=ob['arrTime'],
                                stops=ob['stops'],
                                source="Interpark (êµ­ë‚´ì„  ê°€ëŠ”í¸)"
                            ))
                        return self._sort_and_limit_results(results, max_results, log)
                    
                    # Step 3: ì˜¤ëŠ”í¸ ë¡œë”© ëŒ€ê¸°
                    log("ğŸ• 3ë‹¨ê³„: ì˜¤ëŠ”í¸ ë¡œë”© ëŒ€ê¸°...")
                    return_ready = self._wait_for_domestic_return_view()
                    if return_ready:
                        log("âœ… ì˜¤ëŠ”í¸ í™”ë©´ í™•ì¸ë¨")
                    
                    if not return_ready:
                        log("âš ï¸ ì˜¤ëŠ”í¸ í™”ë©´ ë¡œë”© ì‹¤íŒ¨ - ê°€ëŠ”í¸ë§Œ ë°˜í™˜")
                        for ob in outbound_flights:
                            results.append(FlightResult(
                                airline=ob['airline'],
                                price=ob['price'],
                                departure_time=ob['depTime'],
                                arrival_time=ob['arrTime'],
                                stops=ob['stops'],
                                source="Interpark (êµ­ë‚´ì„  ê°€ëŠ”í¸)"
                            ))
                        return self._sort_and_limit_results(results, max_results, log)
                    
                    # Step 4: ì˜¤ëŠ”í¸ ë°ì´í„° ì¶”ì¶œ
                    log("ğŸ“‹ 4ë‹¨ê³„: ì˜¤ëŠ”í¸ ëª©ë¡ ì¶”ì¶œ ì¤‘...")
                    time.sleep(scraper_config.DOMESTIC_RETURN_POST_CLICK_SETTLE_SECONDS)
                    return_flights = self._extract_domestic_flights_data()
                    log(f"âœ… ì˜¤ëŠ”í¸ {len(return_flights)}ê°œ ë°œê²¬")
                    
                    # Step 5: ê°€ëŠ”í¸ + ì˜¤ëŠ”í¸ ê²°í•©í•˜ì—¬ ì™•ë³µ ê²°ê³¼ ìƒì„±
                    log("ğŸ”— 5ë‹¨ê³„: ê°€ëŠ”í¸/ì˜¤ëŠ”í¸ ê²°í•© ì¤‘...")
                    
                    if outbound_flights and return_flights:
                        log(
                            f"âš¡ ê°€ëŠ”í¸/ì˜¤ëŠ”í¸ ì¡°í•© ê³„ì‚° ì¤‘... "
                            f"(ìƒìœ„ {scraper_config.DOMESTIC_COMBINATION_TOP_N}Ã—"
                            f"{scraper_config.DOMESTIC_COMBINATION_TOP_N})"
                        )
                        results = self._combine_domestic_round_trip(
                            outbound_flights,
                            return_flights,
                            max_results=max_results,
                        )
                        log(f"âœ… ìµœì €ê°€ ê¸°ì¤€ ìƒìœ„ {len(results)}ê°œ ì¡°í•© ë°˜í™˜")
                    else:
                        # ê°€ëŠ”í¸ë§Œ/ì˜¤ëŠ”í¸ë§Œ ìˆëŠ” ê²½ìš°
                        for ob in outbound_flights:
                            results.append(FlightResult(
                                airline=ob['airline'],
                                price=ob['price'],
                                departure_time=ob['depTime'],
                                arrival_time=ob['arrTime'],
                                stops=ob['stops'],
                                source="Interpark (êµ­ë‚´ì„  í¸ë„)"
                            ))
                    
                    return self._sort_and_limit_results(results, max_results, log)
                    
                except Exception as e:
                    log(f"âš ï¸ êµ­ë‚´ì„  ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                    logger.error(f"Domestic error: {e}", exc_info=True)

            
            if found_data:
                log("ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ! ì¶”ì¶œ ì‹œì‘")
                
                # í˜ì´ì§€ ì•ˆì •í™” ëŒ€ê¸°
                time.sleep(scraper_config.SEARCH_PAGE_STABILIZE_SECONDS)
                
                if is_domestic:
                    # êµ­ë‚´ì„  í¸ë„: ë²„íŠ¼ ê¸°ë°˜ ì¶”ì¶œ
                    log("ğŸ‡°ğŸ‡· êµ­ë‚´ì„  í¸ë„ ì¶”ì¶œ")
                    results = self._extract_domestic_prices()

                else:
                    # êµ­ì œì„ : ê¸°ì¡´ ì¶”ì¶œ ë¡œì§
                    results = self._extract_prices()

                if not results:
                    raise DataExtractionError("ìë™ ì¶”ì¶œ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            else:
                log("ë°ì´í„°ê°€ ì¶©ë¶„íˆ ë¡œë“œë˜ì§€ ì•Šì•˜ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                entered_manual = self._enter_manual_mode(
                    url=url,
                    profile_dir=profile_dir,
                    is_domestic=is_domestic,
                    log_func=log,
                    reopen_visible=auto_headless,
                )
                if not entered_manual:
                    raise ManualModeActivationError("ê²°ê³¼ ë¡œë”© ì‹¤íŒ¨ í›„ ìˆ˜ë™ ëª¨ë“œ ì „í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")

            results = self._sort_and_limit_results(results, max_results, log)
            if results:
                log(f"âœ… ìë™ ì¶”ì¶œ ì„±ê³µ: {len(results)}ê°œ")

                
        except DataExtractionError as e:
            log(f"âš ï¸ {e} - ìˆ˜ë™ ëª¨ë“œë¡œ ì „í™˜")
            entered_manual = self._enter_manual_mode(
                url=url,
                profile_dir=profile_dir,
                is_domestic=is_domestic,
                log_func=log,
                reopen_visible=auto_headless,
            )
            if not entered_manual:
                raise ManualModeActivationError("ìë™ ì¶”ì¶œ ê²°ê³¼ ì—†ìŒ ì´í›„ ìˆ˜ë™ ëª¨ë“œ ì „í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.") from e
        except ManualModeActivationError:
            raise
        except Exception as e:
            logger.error(f"Playwright error: {e}", exc_info=True)
            if emit:
                emit(f"ì˜¤ë¥˜ ë°œìƒ: {e}")
            entered_manual = self._enter_manual_mode(
                url=url,
                profile_dir=profile_dir,
                is_domestic=is_domestic,
                log_func=log,
                reopen_visible=auto_headless,
            )
            if not entered_manual:
                raise ManualModeActivationError("ì˜¤ë¥˜ ë³µêµ¬ ì¤‘ ìˆ˜ë™ ëª¨ë“œ ì „í™˜ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.") from e
        
        finally:
            # ìˆ˜ë™ ëª¨ë“œê°€ ì•„ë‹ˆë©´ ë¸Œë¼ìš°ì € ì •ë¦¬ (ë¦¬ì†ŒìŠ¤ ëˆ„ìˆ˜ ë°©ì§€)
            if not self.manual_mode:
                self.close()
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë¡œê¹…
            elapsed_time = time.time() - search_start_time
            result_count = len(results)
            logger.info(f"ğŸ“Š ê²€ìƒ‰ ì™„ë£Œ - ì†Œìš”ì‹œê°„: {elapsed_time:.1f}ì´ˆ, ê²°ê³¼: {result_count}ê±´")
            if emit:
                emit(f"ğŸ“Š ê²€ìƒ‰ ì™„ë£Œ ({elapsed_time:.1f}ì´ˆ, {result_count}ê±´)")
        
        return results

    
    def _extract_domestic_flights_data(self) -> list:
        """êµ­ë‚´ì„ : ìŠ¤í¬ë¡¤í•˜ë©° í˜„ì¬ í™”ë©´ì˜ í•­ê³µí¸ ë°ì´í„° ì¶”ì¶œ"""
        if not self.page:
            return []
        
        all_flights = {}  # ì¤‘ë³µ ì œê±°ìš© dict (key: airline+time+price)
        
        # ìŠ¤í¬ë¡¤ ì¶”ì  ë³€ìˆ˜ ì´ˆê¸°í™”
        self._no_scroll_count = 0
        self._no_new_count = 0
        self._bottom_count = 0  # ìµœí•˜ë‹¨ ë„ë‹¬ ì—°ì† íšŸìˆ˜
        
        # Python í•­ê³µì‚¬ ë¦¬ìŠ¤íŠ¸ë¥¼ JS ë°°ì—´ ë¬¸ìì—´ë¡œ ë³€í™˜
        airlines_js = str(self.DOMESTIC_AIRLINES)
        
        try:
            # ìŠ¤í¬ë¡¤í•˜ë©° ìˆ˜ì§‘ (ìµœëŒ€ íšŸìˆ˜ ë„ë‹¬ ë˜ëŠ” ìŠ¤í¬ë¡¤ ì¢…ë£Œ ì‹œ ì¤‘ë‹¨)
            for scroll_i in range(scraper_config.DOMESTIC_MAX_SCROLLS):
                js_script = ScraperScripts.get_domestic_list_script(airlines_js)
                
                batch = self.page.evaluate(js_script)
                
                # ì¤‘ë³µ ì œê±°í•˜ë©° ì¶”ê°€
                new_count = 0
                for f in batch:
                    # í‚¤ ìƒì„± ë°©ì‹ ë³€ê²½ (ë„ì°©ì‹œê°„ í¬í•¨)
                    key = f.get('key', f'{f["airline"]}_{f["depTime"]}_{f["arrTime"]}_{f["price"]}')
                    if key not in all_flights:
                        all_flights[key] = f
                        new_count += 1
                
                scroll_script = ScraperScripts.get_scroll_check_script()
                scroll_result = self.page.evaluate(scroll_script)
                
                time.sleep(scraper_config.DOMESTIC_SCROLL_PAUSE_SECONDS)
                
                can_scroll = scroll_result.get('canScroll', False)
                reached_bottom = scroll_result.get('reachedBottom', False)
                
                # ìµœí•˜ë‹¨ ë„ë‹¬ + ìƒˆ ë°ì´í„° ì—†ìŒ ë¡œì§
                if reached_bottom and new_count == 0:
                    self._bottom_count += 1
                    logger.debug(f"ìµœí•˜ë‹¨ ë„ë‹¬ ì²´í¬: {self._bottom_count}/3íšŒ (ìƒˆ í•­ëª© ì—†ìŒ)")
                    if self._bottom_count >= 3:
                        logger.debug(f"âœ… ìŠ¤í¬ë¡¤ ìµœí•˜ë‹¨ ë„ë‹¬ í™•ì¸: {len(all_flights)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ, ë‹¤ìŒ ë‹¨ê³„ë¡œ ì§„í–‰")
                        break
                    time.sleep(scraper_config.DOMESTIC_SCROLL_BOTTOM_PAUSE_SECONDS)
                    continue
                else:
                    self._bottom_count = 0  # ë¦¬ì…‹
                
                # ìŠ¤í¬ë¡¤ì´ ë” ì´ìƒ ë¶ˆê°€ëŠ¥í•˜ë©´ ì¢…ë£Œ
                if not can_scroll:
                    self._no_scroll_count += 1
                    if self._no_scroll_count >= 3:
                        logger.debug(f"ìŠ¤í¬ë¡¤ ë ë„ë‹¬: ë” ì´ìƒ ìŠ¤í¬ë¡¤í•  ìˆ˜ ì—†ìŒ ({len(all_flights)}ê°œ ìˆ˜ì§‘)")
                        break
                else:
                    self._no_scroll_count = 0
                
                # ìƒˆ í•­ëª© ì—†ìœ¼ë©´ ì¹´ìš´íŠ¸ (lazy loading ëŒ€ê¸°)
                if new_count == 0:
                    self._no_new_count += 1
                    if self._no_new_count >= 8:  # 8íšŒ ì—°ì† ìƒˆ í•­ëª© ì—†ìœ¼ë©´ ì¢…ë£Œ
                        logger.debug(f"ìŠ¤í¬ë¡¤ ì¡°ê¸° ì¢…ë£Œ: {self._no_new_count}íšŒ ì—°ì† ìƒˆ í•­ëª© ì—†ìŒ ({len(all_flights)}ê°œ ìˆ˜ì§‘)")
                        break
                else:
                    self._no_new_count = 0
            
            result_list = list(all_flights.values())
            logger.info(f"êµ­ë‚´ì„  {len(result_list)}ê°œ í•­ê³µí¸ ì¶”ì¶œ (ìŠ¤í¬ë¡¤ {scroll_i+1}íšŒ)")
            return result_list
            
        except Exception as e:
            logger.error(f"Extract domestic data error: {e}", exc_info=True)
            return []

    
    def _extract_domestic_prices(self) -> List[FlightResult]:

        """êµ­ë‚´ì„  ì „ìš©: button ê¸°ë°˜ í•­ê³µí¸ ì •ë³´ ì¶”ì¶œ"""
        if not self.page:
            return []
        
        results = []
        logger.info("ğŸ‡°ğŸ‡· êµ­ë‚´ì„  í•­ê³µí¸ ì¶”ì¶œ ì‹œì‘...")
        
        # Python í•­ê³µì‚¬ ë¦¬ìŠ¤íŠ¸ë¥¼ JS ë°°ì—´ ë¬¸ìì—´ë¡œ ë³€í™˜
        airlines_js = str(self.DOMESTIC_AIRLINES)
        
        try:
            js_script = ScraperScripts.get_domestic_prices_script(airlines_js)
            
            extracted = self.page.evaluate(js_script)
            seen = set()
            for item in extracted:
                price = item.get('price', 0)
                dep_time = item.get('depTime', '')
                arr_time = item.get('arrTime', '')
                if price <= 0 or not dep_time or not arr_time:
                    continue
                key = f"{item.get('airline', 'Unknown')}_{dep_time}_{arr_time}_{price}"
                if key in seen:
                    continue
                seen.add(key)
                flight = FlightResult(
                    airline=item.get('airline', 'Unknown'),
                    price=price,
                    departure_time=dep_time,
                    arrival_time=arr_time,
                    stops=item.get('stops', 0),
                    source="Interpark (êµ­ë‚´ì„ )",
                    return_departure_time='',
                    return_arrival_time='',
                    return_stops=0,
                    is_round_trip=False
                )
                results.append(flight)
            
            logger.info(f"ğŸ‡°ğŸ‡· êµ­ë‚´ì„  ì¶”ì¶œ ì™„ë£Œ: {len(results)}ê°œ")
            
        except Exception as e:
            logger.error(f"Domestic extraction error: {e}", exc_info=True)
        
        return results

    
    def _extract_prices(self) -> List[FlightResult]:

        """JavaScriptë¥¼ ì´ìš©í•´ í˜„ì¬ í˜ì´ì§€ì—ì„œ í•­ê³µê¶Œ ì •ë³´ ì¶”ì¶œ (ìŠ¤í¬ë¡¤í•˜ë©° ì ì§„ì  ìˆ˜ì§‘)"""
        if not self.page:
            return []
        
        all_results_dict = {}  # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•œ ë”•ì…”ë„ˆë¦¬ (Key: unique_id)
        max_scrolls = scraper_config.INTERNATIONAL_MAX_SCROLLS
        pause_time = scraper_config.SCROLL_PAUSE_TIME
        
        logger.info(f"ğŸ“œ ì ì§„ì  ì¶”ì¶œ ì‹œì‘ (ìµœëŒ€ {max_scrolls}íšŒ ìŠ¤í¬ë¡¤)...")
        
        try:
            previous_height = 0
            
            for i in range(max_scrolls):
                # 1. í˜„ì¬ í™”ë©´ ë°ì´í„° ì¶”ì¶œ
                js_script = ScraperScripts.get_international_prices_script()
                
                step_results = self.page.evaluate(js_script)
                if not step_results and i == 0:
                    fallback_script = ScraperScripts.get_international_prices_fallback_script()
                    fallback_results = self.page.evaluate(fallback_script)
                    if fallback_results:
                        logger.info("êµ­ì œì„  ë³´ì¡° ìŠ¤í¬ë¦½íŠ¸ë¡œ ì¶”ì¶œ ì‹œë„")
                        step_results = fallback_results
                
                # ê²°ê³¼ ë³‘í•©
                current_count = 0
                for item in step_results:
                    # ê³ ìœ  í‚¤ ìƒì„±: í¸ë³„ í•µì‹¬ ì •ë³´ ì „ì²´ë¥¼ í¬í•¨í•´ ê³¼ë„í•œ dedup ë°©ì§€
                    unique_key = (
                        f"{item.get('airline', '')}|{item.get('price', 0)}|"
                        f"{item.get('depTime', '')}|{item.get('arrTime', '')}|{item.get('stops', 0)}|"
                        f"{item.get('retDepTime', '')}|{item.get('retArrTime', '')}|{item.get('retStops', 0)}"
                    )
                    if unique_key not in all_results_dict:
                        all_results_dict[unique_key] = item
                        current_count += 1
                
                logger.debug(f"âœ¨ ìŠ¤í¬ë¡¤ {i+1}: ìƒˆë¡œìš´ ê²°ê³¼ {current_count}ê°œ ì¶”ê°€ (ì´ {len(all_results_dict)}ê°œ)")
                
                # 2. ìŠ¤í¬ë¡¤ ì§„í–‰
                self.page.evaluate("window.scrollTo(0, document.body.scrollHeight)")
                self.page.wait_for_timeout(pause_time * 1000)
                
                # 3. ë†’ì´ ë³€í™” ì²´í¬ (ì¢…ë£Œ ì¡°ê±´)
                new_height = self.page.evaluate("document.body.scrollHeight")
                if new_height == previous_height and i > 2: # ì´ˆë°˜ì—ëŠ” ë³€í™”ê°€ ì—†ì–´ë„ ì‹œë„í•´ë³¼ë§Œ í•¨
                     logger.debug("ğŸ“œ ë” ì´ìƒ ìƒˆë¡œìš´ ë‚´ìš©ì´ ë¡œë”©ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
                     break
                previous_height = new_height

        except Exception as e:
            logger.error(f"Extraction error: {e}", exc_info=True)
        
        # ë”•ì…”ë„ˆë¦¬ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        results = []
        if not all_results_dict:
            fallback_script = ScraperScripts.get_international_prices_fallback_script()
            fallback_results = self.page.evaluate(fallback_script)
            if fallback_results:
                for item in fallback_results:
                    unique_key = (
                        f"{item.get('airline', '')}|{item.get('price', 0)}|"
                        f"{item.get('depTime', '')}|{item.get('arrTime', '')}|{item.get('stops', 0)}|"
                        f"{item.get('retDepTime', '')}|{item.get('retArrTime', '')}|{item.get('retStops', 0)}"
                    )
                    all_results_dict[unique_key] = item
        for item in all_results_dict.values():
             flight = FlightResult(
                airline=item.get('airline', 'Unknown'),
                price=item.get('price', 0),
                departure_time=item.get('depTime', ''),
                arrival_time=item.get('arrTime', ''),
                stops=item.get('stops', 0),
                source="Interpark (Auto)",
                return_departure_time=item.get('retDepTime', ''),
                return_arrival_time=item.get('retArrTime', ''),
                return_stops=item.get('retStops', 0),
                is_round_trip=item.get('isRoundTrip', False)
            )
             results.append(flight)
             
        return results
    
    def extract_from_current_page(self) -> List[FlightResult]:
        """ìˆ˜ë™ ëª¨ë“œ: í˜„ì¬ í˜ì´ì§€ì—ì„œ ë°ì´í„° ì¶”ì¶œ (ì‚¬ìš©ìê°€ í˜¸ì¶œ)"""
        if self._last_is_domestic:
            return self._extract_domestic_prices()
        return self._extract_prices()
    
    def close(self):
        """ë¸Œë¼ìš°ì € ë° ë¦¬ì†ŒìŠ¤ ì •ë¦¬"""
        resources = [
            ('page', self.page),
            ('context', self.context),
            ('browser', self.browser),
            ('playwright', self.playwright)
        ]
        
        for name, resource in resources:
            if resource:
                try:
                    if name == 'playwright':
                        resource.stop()
                    else:
                        resource.close()
                except Exception as e:
                    logger.debug(f"{name} ì •ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")
                finally:
                    setattr(self, name, None)
        
        self.manual_mode = False
    
    def is_manual_mode(self) -> bool:
        """ìˆ˜ë™ ëª¨ë“œ ì—¬ë¶€ í™•ì¸"""
        return self.manual_mode and self.page is not None


class FlightSearcher:
    """í†µí•© í•­ê³µê¶Œ ê²€ìƒ‰ ì—”ì§„"""

    _cache_lock = threading.Lock()
    _search_cache: "OrderedDict[tuple, tuple[float, List[Dict[str, Any]]]]" = OrderedDict()
    
    def __init__(self):
        self.scraper = PlaywrightScraper()
        self.last_results: List[FlightResult] = []

    @staticmethod
    def _build_cache_key(
        origin: str,
        destination: str,
        departure_date: str,
        return_date: Optional[str],
        adults: int,
        cabin_class: str,
        max_results: int,
    ) -> tuple:
        return (
            (origin or "").upper(),
            (destination or "").upper(),
            departure_date or "",
            return_date or "",
            int(adults or 1),
            (cabin_class or "ECONOMY").upper(),
            int(max_results or 0),
        )

    @classmethod
    def _prune_cache_locked(cls, now: float) -> None:
        ttl = max(1, int(getattr(scraper_config, "SEARCH_CACHE_TTL_SECONDS", 180)))
        max_entries = max(1, int(getattr(scraper_config, "SEARCH_CACHE_MAX_ENTRIES", 64)))

        expired_keys = []
        for key, (saved_at, _) in cls._search_cache.items():
            if now - saved_at > ttl:
                expired_keys.append(key)
        for key in expired_keys:
            cls._search_cache.pop(key, None)

        while len(cls._search_cache) > max_entries:
            cls._search_cache.popitem(last=False)

    @staticmethod
    def _deserialize_cached_results(payload: List[Dict[str, Any]]) -> List[FlightResult]:
        restored = []
        for row in payload:
            try:
                restored.append(FlightResult(**row))
            except Exception:
                continue
        restored.sort(key=lambda x: x.price if x.price > 0 else float("inf"))
        return restored

    @classmethod
    def _get_cached_results(cls, cache_key: tuple, force_refresh: bool = False) -> Optional[List[FlightResult]]:
        if force_refresh or not getattr(scraper_config, "ENABLE_SEARCH_CACHE", True):
            return None

        now = time.time()
        with cls._cache_lock:
            cls._prune_cache_locked(now)
            item = cls._search_cache.get(cache_key)
            if not item:
                return None
            saved_at, payload = item
            ttl = max(1, int(getattr(scraper_config, "SEARCH_CACHE_TTL_SECONDS", 180)))
            if now - saved_at > ttl:
                cls._search_cache.pop(cache_key, None)
                return None
            cls._search_cache.move_to_end(cache_key)
        return cls._deserialize_cached_results(payload)

    @classmethod
    def _store_cached_results(cls, cache_key: tuple, results: List[FlightResult]) -> None:
        if not results or not getattr(scraper_config, "ENABLE_SEARCH_CACHE", True):
            return

        payload = []
        for item in results:
            try:
                payload.append(item.to_dict())
            except Exception:
                continue
        if not payload:
            return

        now = time.time()
        with cls._cache_lock:
            cls._prune_cache_locked(now)
            cls._search_cache[cache_key] = (now, payload)
            cls._search_cache.move_to_end(cache_key)
            cls._prune_cache_locked(now)

    @classmethod
    def clear_cache(cls) -> None:
        with cls._cache_lock:
            cls._search_cache.clear()
    
    def search(self, origin: str, destination: str, 
               departure_date: str, return_date: Optional[str] = None,
               adults: int = 1, cabin_class: str = "ECONOMY",
               max_results: int = 1000,
               progress_callback: Callable = None,
               force_refresh: bool = False) -> List[FlightResult]:
        """í•­ê³µê¶Œ ê²€ìƒ‰ ì§„ì…ì """
        def emit(msg):
            if progress_callback:
                progress_callback(msg)
            logger.info(msg)
        
        cabin_label = {"ECONOMY": "ì´ì½”ë…¸ë¯¸", "BUSINESS": "ë¹„ì¦ˆë‹ˆìŠ¤", "FIRST": "ì¼ë“±ì„"}.get(cabin_class.upper(), "ì´ì½”ë…¸ë¯¸")
        emit(f"ğŸ” {origin} â†’ {destination} í•­ê³µê¶Œ ê²€ìƒ‰ ì‹œì‘ ({cabin_label})")

        cache_key = self._build_cache_key(
            origin=origin,
            destination=destination,
            departure_date=departure_date,
            return_date=return_date,
            adults=adults,
            cabin_class=cabin_class,
            max_results=max_results,
        )
        cached_results = self._get_cached_results(cache_key, force_refresh=force_refresh)
        if cached_results is not None:
            self.last_results = cached_results
            cheapest = cached_results[0] if cached_results else None
            if cheapest:
                emit(f"âš¡ ìºì‹œ ì‚¬ìš©: {len(cached_results)}ê°œ ê²°ê³¼, ìµœì €ê°€ {cheapest.price:,}ì›")
            else:
                emit("âš¡ ìºì‹œ ì‚¬ìš©: ê²°ê³¼ ì—†ìŒ")
            return cached_results
        
        results = self.scraper.search(
            origin, destination, 
            departure_date, return_date, 
            adults, cabin_class,
            max_results, 
            emit
        )
        self.last_results = results
        
        if results:
            if not self.scraper.is_manual_mode():
                self._store_cached_results(cache_key, results)
            cheapest = results[0]
            emit(f"âœ… ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ë°œê²¬, ìµœì €ê°€ {cheapest.price:,}ì›")
        elif self.scraper.is_manual_mode():
            emit("ğŸ–ï¸ ìˆ˜ë™ ëª¨ë“œ í™œì„±í™” - ë¸Œë¼ìš°ì €ì—ì„œ ê²°ê³¼ ë¡œë”© í›„ 'ì¶”ì¶œ' ë²„íŠ¼ì„ ëˆ„ë¥´ì„¸ìš”")
        else:
            emit("âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        
        return results
    
    def extract_manual(self) -> List[FlightResult]:
        """ìˆ˜ë™ ëª¨ë“œì—ì„œ ë°ì´í„° ì¶”ì¶œ ì¬ì‹œë„"""
        results = self.scraper.extract_from_current_page()
        results.sort(key=lambda x: x.price if x.price > 0 else float('inf'))
        self.last_results = results
        return results
    
    def is_manual_mode(self) -> bool:
        return self.scraper.is_manual_mode()
    
    def close(self):
        self.scraper.close()
    
    def get_cheapest(self) -> Optional[FlightResult]:
        if self.last_results:
            return self.last_results[0]
        return None


class ParallelSearcher:
    """ë‹¤ì¤‘ ê²€ìƒ‰ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•˜ëŠ” ê²€ìƒ‰ ì—”ì§„"""
    
    def __init__(self, max_concurrent: int = 2):
        self.max_concurrent = min(max_concurrent, 4)  # ìµœëŒ€ 4ê°œë¡œ ì œí•œ
        self.results = {}
        self._lock = None
    
    def search_multiple_destinations(self, origin: str, destinations: List[str],
                                     departure_date: str, return_date: Optional[str] = None,
                                     adults: int = 1, cabin_class: str = "ECONOMY",
                                     progress_callback: Callable = None) -> Dict[str, List[FlightResult]]:
        """ì—¬ëŸ¬ ëª©ì ì§€ë¥¼ ë³‘ë ¬ë¡œ ê²€ìƒ‰"""
        import threading
        from concurrent.futures import ThreadPoolExecutor, as_completed
        
        self._lock = threading.Lock()
        self.results = {}
        
        def search_single(dest: str) -> tuple:
            """ë‹¨ì¼ ëª©ì ì§€ ê²€ìƒ‰"""
            searcher = FlightSearcher()
            try:
                def emit(msg):
                    if progress_callback:
                        progress_callback(f"[{dest}] {msg}")
                    logger.info(f"[{dest}] {msg}")
                
                results = searcher.scraper.search(
                    origin, dest, departure_date, return_date, 
                    adults, cabin_class, max_results=500, emit=emit
                )
                return dest, results
            except Exception as e:
                logger.error(f"Parallel search error for {dest}: {e}")
                return dest, []
            finally:
                searcher.close()
        
        if progress_callback:
            progress_callback(f"ğŸš€ ë³‘ë ¬ ê²€ìƒ‰ ì‹œì‘: {len(destinations)}ê°œ ëª©ì ì§€ (ë™ì‹œ {self.max_concurrent}ê°œ)")
        
        with ThreadPoolExecutor(max_workers=self.max_concurrent) as executor:
            futures = {executor.submit(search_single, dest): dest for dest in destinations}
            
            for future in as_completed(futures):
                try:
                    dest, results = future.result()
                    with self._lock:
                        self.results[dest] = results
                        
                    if progress_callback:
                        count = len(results)
                        cheapest = min((r.price for r in results), default=0) if results else 0
                        progress_callback(f"âœ… {dest} ì™„ë£Œ: {count}ê°œ ê²°ê³¼, ìµœì €ê°€ {cheapest:,}ì›")
                except Exception as e:
                    logger.error(f"Future error: {e}")
        
        if progress_callback:
            progress_callback(f"ğŸ ë³‘ë ¬ ê²€ìƒ‰ ì™„ë£Œ: {len(self.results)}ê°œ ëª©ì ì§€")
        
        return self.results
    
    def search_date_range(self, origin: str, destination: str,
                          dates: List[str], return_offset: int = 0,
                          adults: int = 1, cabin_class: str = "ECONOMY",
                          progress_callback: Callable = None) -> Dict[str, tuple]:
        """ì—¬ëŸ¬ ë‚ ì§œë¥¼ ë³‘ë ¬ë¡œ ê²€ìƒ‰"""
        import threading
        from concurrent.futures import ThreadPoolExecutor, as_completed
        from datetime import datetime, timedelta
        
        self._lock = threading.Lock()
        date_results = {}
        
        def search_single_date(dep_date: str) -> tuple:
            """ë‹¨ì¼ ë‚ ì§œ ê²€ìƒ‰"""
            ret_date = None
            if return_offset > 0:
                try:
                    dt = datetime.strptime(dep_date, "%Y%m%d")
                    ret_date = (dt + timedelta(days=return_offset)).strftime("%Y%m%d")
                except Exception:
                    pass
            
            searcher = FlightSearcher()
            try:
                # ì¡°ìš©íˆ ì‹¤í–‰
                results = searcher.scraper.search(
                    origin, destination, dep_date, ret_date,
                    adults, cabin_class, max_results=100, emit=lambda msg: None
                )
                
                if results:
                    cheapest = min(results, key=lambda x: x.price)
                    return dep_date, (cheapest.price, cheapest.airline)
                return dep_date, (0, "N/A")
            except Exception as e:
                logger.error(f"Date search error for {dep_date}: {e}")
                return dep_date, (0, "Error")
            finally:
                searcher.close()
        
        if progress_callback:
            progress_callback(f"ğŸš€ ë‚ ì§œ ë³‘ë ¬ ê²€ìƒ‰: {len(dates)}ì¼ (ë™ì‹œ {self.max_concurrent}ê°œ)")
        
        with ThreadPoolExecutor(max_workers=self.max_concurrent) as executor:
            futures = {executor.submit(search_single_date, d): d for d in dates}
            completed = 0
            
            for future in as_completed(futures):
                try:
                    dep_date, price_info = future.result()
                    with self._lock:
                        date_results[dep_date] = price_info
                        completed += 1
                    
                    if progress_callback:
                        price, airline = price_info
                        if price > 0:
                            progress_callback(f"ğŸ“… {dep_date}: {price:,}ì› ({airline}) [{completed}/{len(dates)}]")
                        else:
                            progress_callback(f"ğŸ“… {dep_date}: ê²°ê³¼ ì—†ìŒ [{completed}/{len(dates)}]")
                except Exception as e:
                    logger.error(f"Future error: {e}")
        
        if progress_callback:
            progress_callback(f"ğŸ ë‚ ì§œ ê²€ìƒ‰ ì™„ë£Œ: {len(date_results)}ì¼")
        
        return date_results


if __name__ == "__main__":
    searcher = FlightSearcher()
    try:
        print("\n=== Playwright í…ŒìŠ¤íŠ¸ (ì„œìš¸ â†’ ë„ì¿„) ===")
        # í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ 30ì¼ í›„ ë‚ ì§œ ìƒì„±
        from datetime import datetime, timedelta
        d1 = (datetime.now() + timedelta(days=30)).strftime("%Y%m%d")
        d2 = (datetime.now() + timedelta(days=35)).strftime("%Y%m%d")
        
        results = searcher.search("ICN", "NRT", d1, d2)
        
        if results:
            print(f"\n{len(results)}ê°œ ê²°ê³¼:")
            for i, r in enumerate(results[:5], 1):
                stops = "ì§í•­" if r.stops == 0 else f"{r.stops}íšŒ ê²½ìœ "
                print(f"{i}. {r.airline} - {r.price:,}ì› | {r.departure_time} -> {r.arrival_time}")
        else:
            print("ê²°ê³¼ ì—†ìŒ ë˜ëŠ” ìˆ˜ë™ ëª¨ë“œ ì „í™˜ë¨")
    finally:
        searcher.close()
